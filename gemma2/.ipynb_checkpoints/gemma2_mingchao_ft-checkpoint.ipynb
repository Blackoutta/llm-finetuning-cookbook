{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c390fd50-1301-40e4-add9-cb605a18705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/root/autodl-tmp/hf\n",
      "env: HF_HUB_CACHE=/root/autodl-tmp/hf\n"
     ]
    }
   ],
   "source": [
    "# %env HF_ENDPOINT=https://hf-mirror.com\n",
    "%env HF_HOME=/root/autodl-tmp/hf\n",
    "%env HF_HUB_CACHE=/root/autodl-tmp/hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d74b36d-cc23-458d-8b60-e091e0ffb41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True,\n",
    "                        text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf71e755-5656-4712-b25f-7967177552a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -q -U bitsandbytes\n",
    "# !pip3 install -q -U peft\n",
    "# !pip3 install -q -U trl\n",
    "# !pip3 install -q -U accelerate\n",
    "# !pip3 install -q -U datasets\n",
    "# !pip3 install -q -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839379da-f7f4-4415-8cdc-a05c6b32bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88a4ed3-7ee7-4108-8f33-bedf2af10b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669e1e07-8839-4ffa-bfaa-536c23f5ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9267507c4c66453fb4387a50347884c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"google/gemma-2-9b\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0}, attn_implementation='eager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a54116-938c-40ba-af93-63c1a06ce0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e91279c-fc77-45f2-b867-aca3bfe90248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"synthetic_data_merge.jsonl\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64be43d3-7e87-4c15-bc08-b8e78768979b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 647\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8068f364-d316-4185-9ba2-ba5516d0feef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>合轴流程的主要目的是什么？</td>\n",
       "      <td>合轴流程主要目的是在单位时间内提高团队输出效率。它通过穿插更多角色的操作来利用长脱手动作导致...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>在合轴过程中，哪些技能会被用到？</td>\n",
       "      <td>合轴流程中会用到声骸技能（Q）、常态攻击（A）、共鸣技能（E）、重击（Z）、共鸣解放（R）和...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>给出一个合轴流程的例子？</td>\n",
       "      <td>比如推荐配队中，卡卡罗的技能循环是QEAEAEAZ，维里奈是QTE满后Q，吟霖是EAAAAA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             question                                             answer\n",
       "644     合轴流程的主要目的是什么？  合轴流程主要目的是在单位时间内提高团队输出效率。它通过穿插更多角色的操作来利用长脱手动作导致...\n",
       "645  在合轴过程中，哪些技能会被用到？  合轴流程中会用到声骸技能（Q）、常态攻击（A）、共鸣技能（E）、重击（Z）、共鸣解放（R）和...\n",
       "646      给出一个合轴流程的例子？  比如推荐配队中，卡卡罗的技能循环是QEAEAEAZ，维里奈是QTE满后Q，吟霖是EAAAAA..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas().tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aa97839-3f3f-47dd-90ec-998d7bd54568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    text = f\"\"\"问题: {data_point[\"question\"]}\\n 回答: {data_point[\"answer\"]}\"\"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd50b04e-237b-405a-8053-08ed7a780e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the \"prompt\" column in the dataset\n",
    "text_column = [generate_prompt(data_point) for data_point in dataset]\n",
    "dataset = dataset.add_column(\"prompt\", text_column)\n",
    "\n",
    "dataset = dataset.shuffle(seed=1234)  # Shuffle dataset here\n",
    "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5897d950-51d1-4f32-8c16-c53327621e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = dataset.train_test_split(test_size=0.05)\n",
    "train_data = split[\"train\"]\n",
    "test_data = split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "640bed61-40ad-4865-bcbd-84d53eabace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 614\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b7437a-0620-4f02-b44e-8eccefb3d255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'prompt', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 33\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031dd83c-a017-458f-a26a-b793ff9ce887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“合轴流程合轴”中如何操作配队今汐+吟霖+维里奈？</td>\n",
       "      <td>具体输出手法包括：以配队今汐+吟霖+维里奈为例：吟霖ZRZEZEAAZ（重击后摇靠技能打断，...</td>\n",
       "      <td>问题: “合轴流程合轴”中如何操作配队今汐+吟霖+维里奈？\\n 回答: 具体输出手法包括：以...</td>\n",
       "      <td>[2, 13240, 235292, 1080, 235697, 239302, 54201...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>玩家在游戏中需要与什么生物对抗？</td>\n",
       "      <td>玩家需要与从末日灾难中诞生的怪物“幻象”对抗。</td>\n",
       "      <td>问题: 玩家在游戏中需要与什么生物对抗？\\n 回答: 玩家需要与从末日灾难中诞生的怪物“幻象...</td>\n",
       "      <td>[2, 13240, 235292, 235248, 34673, 235473, 1585...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>在合轴过程中，哪些技能会被用到？</td>\n",
       "      <td>合轴流程中会用到声骸技能（Q）、常态攻击（A）、共鸣技能（E）、重击（Z）、共鸣解放（R）和...</td>\n",
       "      <td>问题: 在合轴过程中，哪些技能会被用到？\\n 回答: 合轴流程中会用到声骸技能（Q）、常态攻...</td>\n",
       "      <td>[2, 13240, 235292, 19183, 235697, 239302, 6393...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question  \\\n",
       "0  “合轴流程合轴”中如何操作配队今汐+吟霖+维里奈？   \n",
       "1           玩家在游戏中需要与什么生物对抗？   \n",
       "2           在合轴过程中，哪些技能会被用到？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  具体输出手法包括：以配队今汐+吟霖+维里奈为例：吟霖ZRZEZEAAZ（重击后摇靠技能打断，...   \n",
       "1                            玩家需要与从末日灾难中诞生的怪物“幻象”对抗。   \n",
       "2  合轴流程中会用到声骸技能（Q）、常态攻击（A）、共鸣技能（E）、重击（Z）、共鸣解放（R）和...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  问题: “合轴流程合轴”中如何操作配队今汐+吟霖+维里奈？\\n 回答: 具体输出手法包括：以...   \n",
       "1  问题: 玩家在游戏中需要与什么生物对抗？\\n 回答: 玩家需要与从末日灾难中诞生的怪物“幻象...   \n",
       "2  问题: 在合轴过程中，哪些技能会被用到？\\n 回答: 合轴流程中会用到声骸技能（Q）、常态攻...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [2, 13240, 235292, 1080, 235697, 239302, 54201...   \n",
       "1  [2, 13240, 235292, 235248, 34673, 235473, 1585...   \n",
       "2  [2, 13240, 235292, 19183, 235697, 239302, 6393...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.to_pandas().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05d7074e-6c37-4a79-8477-b13b60fd6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6a9d06f-89b3-49ef-96b0-81e01c6c5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "def find_all_linear_names(model):\n",
    "  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "  lora_module_names = set()\n",
    "  for name, module in model.named_modules():\n",
    "    if isinstance(module, cls):\n",
    "      names = name.split('.')\n",
    "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names: # needed for 16-bit\n",
    "      lora_module_names.remove('lm_head')\n",
    "  return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b8bd623-6702-4d97-8fa8-d30cd8ec274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v_proj', 'o_proj', 'gate_proj', 'up_proj', 'q_proj', 'k_proj', 'down_proj']\n"
     ]
    }
   ],
   "source": [
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d6bc770-794d-49f2-89af-849b90920dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    target_modules=modules,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9f528a-8b99-4d45-9eb0-769fca51378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 216072192 | total: 9457778176 | Percentage: 2.2846%\n"
     ]
    }
   ],
   "source": [
    "trainable, total = model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e56b2f46-44e9-4b71-8da7-f7dfe86cd176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import os\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "save_dir = '/root/autodl-tmp/models'\n",
    "save_name = \"google/gemma-2-9b-mingchao-ft\" \n",
    "out_dir = os.path.join(save_dir, save_name)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    peft_config=lora_config,\n",
    "    args=SFTConfig(\n",
    "        overwrite_output_dir=True,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=2,\n",
    "        eval_accumulation_steps=1,\n",
    "        warmup_ratio=0.1,\n",
    "        learning_rate=2e-5,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=0.05,\n",
    "        output_dir=out_dir,\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        eval_strategy=\"no\",\n",
    "        eval_steps=0.2,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=0.1,\n",
    "        report_to=\"tensorboard\",\n",
    "        num_train_epochs=3,\n",
    "        max_seq_length=512,\n",
    "        dataset_text_field=\"prompt\",\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c67e286-a560-476f-a113-00b280563fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
      "\tlogging_steps: 0.05 (from args) != 12 (from trainer_state.json)\n",
      "\teval_steps: 0.2 (from args) != 47 (from trainer_state.json)\n",
      "\tsave_steps: 0.1 (from args) != 24 (from trainer_state.json)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/root/miniconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='231' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [231/231 00:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>1.017800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=231, training_loss=0.06589622105354871, metrics={'train_runtime': 26.2329, 'train_samples_per_second': 70.217, 'train_steps_per_second': 8.806, 'total_flos': 5525899002839040.0, 'train_loss': 0.06589622105354871, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74677944-0930-4771-970a-bc82a2a48320",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d5fc2-cecf-409d-8f71-e045c007ca9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
