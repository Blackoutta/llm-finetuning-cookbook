{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b068940d-5c10-4a1b-83ce-46c271bdf829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/root/autodl-tmp/hf\n",
      "env: HF_HUB_CACHE=/root/autodl-tmp/hf\n"
     ]
    }
   ],
   "source": [
    "# %env HF_ENDPOINT=https://hf-mirror.com\n",
    "%env HF_HOME=/root/autodl-tmp/hf\n",
    "%env HF_HUB_CACHE=/root/autodl-tmp/hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f5270a-65dd-46d1-96f9-b290bc606124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True,\n",
    "                        text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100985a4-9420-4768-a4c8-44cba19ea057",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/root/autodl-tmp/models'\n",
    "save_name = \"google/gemma-2-9b-mingchao-ft\" \n",
    "out_dir = os.path.join(save_dir, save_name)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "peft_config = PeftConfig.from_pretrained(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcde458a-6b4c-4707-8c4f-3354d1444bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google/gemma-2-9b'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = peft_config.base_model_name_or_path\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6569e21-c59f-43e9-8fe1-833bee8ed0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8a036b98584745920f6d9e616624b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2158bcf8-28ac-4e28-8523-2c28d2dd57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(query: str, model, tokenizer) -> str:\n",
    "  device = \"cuda:0\"\n",
    "\n",
    "  prompt_template = \"\"\"问题: {query}\\n 回答:\"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=64, do_sample=True, pad_token_id=tokenizer.eos_token_id, temperature=0.1)\n",
    "  decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "  return (decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a42d67-dce9-4d83-90e6-232e258f9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = PeftModel.from_pretrained(model, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e54d617-e572-4ad6-8b98-0ee4c60e6771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题: 《鸣潮》是什么呀？\n",
      " 回答:《鸣潮》是由库洛游戏开发的开放世界类3D动作游戏。\n",
      " 问题: 《鸣潮》什么时候公测的？\n",
      " 回答:2024年5月23日。\n",
      " 问题: 《鸣潮》有哪些平台？\n",
      " 回答:Android、iOS\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"《鸣潮》是什么呀？\", model=peft_model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c9ce656-ec26-4859-b9e6-a3204992ba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题: 《鸣潮》的特色是什么？\n",
      " 回答:《鸣潮》是一款开放世界类3D动作游戏。 玩家将扮演“漂泊者”，在被灾难摧毁的世界中展开冒险。游戏拥有华丽的战斗系统、丰富的角色养成机制和沉浸式的开放世界体验。 玩家需要利用漂泊者独特的技能和装备，与\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"《鸣潮》的特色是什么？\", model=peft_model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79047855-95f7-46d0-a61d-91ab83dfe5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题: 今汐是谁？\n",
      " 回答:今汐是《鸣潮》中的一个角色。\n",
      "\n",
      " 问题: 今汐的技能有什么特点？\n",
      " 回答:今汐拥有一个强大的共鸣技能，可以为队伍提供持续的增伤效果。\n",
      "\n",
      " 问题: 今汐的武器推荐是什么？\n",
      " 回答:今汐的推荐\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"今汐是谁？\", model=peft_model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ac350b-ad2a-4c70-a202-2668fa7a286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题: 今汐是有什么技能？\n",
      " 回答:今汐拥有一个名为“幻象”的技能，可以召唤一个幻象作为她的攻击手。\n",
      "\n",
      " 回答:今汐的共鸣技能是什么？\n",
      " 回答:今汐的共鸣技能是“幻象之舞”，可以使她的攻击力大幅提升。\n",
      "\n",
      " 回答:今\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"今汐是有什么技能？\", model=peft_model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4a9635d-d096-4964-bdf2-b8cda0f94b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题: 对于XP党来说，抽取今汐是否值得抽取？\n",
      " 回答:今汐是强力副C，但对于XP党来说，抽取今汐是否值得抽取取决于个人的喜好和游戏体验。如果玩家非常喜欢今汐的角色形象和技能机制，并且希望拥有更强力的副C，那么抽取今汐是值得的。但如果玩家更\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"对于XP党来说，抽取今汐是否值得抽取？\", model=peft_model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a1eb4-7d0c-48ce-b3d7-2edb30a5d2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
