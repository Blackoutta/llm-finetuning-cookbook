{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b068940d-5c10-4a1b-83ce-46c271bdf829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/root/autodl-tmp/hf\n",
      "env: HF_HUB_CACHE=/root/autodl-tmp/hf\n"
     ]
    }
   ],
   "source": [
    "# %env HF_ENDPOINT=https://hf-mirror.com\n",
    "%env HF_HOME=/root/autodl-tmp/hf\n",
    "%env HF_HUB_CACHE=/root/autodl-tmp/hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f5270a-65dd-46d1-96f9-b290bc606124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True,\n",
    "                        text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100985a4-9420-4768-a4c8-44cba19ea057",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/root/autodl-tmp/models'\n",
    "save_name = \"google/gemma-2-9b-mingchao-ft\" \n",
    "out_dir = os.path.join(save_dir, save_name)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "peft_config = PeftConfig.from_pretrained(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcde458a-6b4c-4707-8c4f-3354d1444bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google/gemma-2-9b'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = peft_config.base_model_name_or_path\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6569e21-c59f-43e9-8fe1-833bee8ed0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9269df2489224df1949f200a96557787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2158bcf8-28ac-4e28-8523-2c28d2dd57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(query: str, model, tokenizer) -> str:\n",
    "  device = \"cuda:0\"\n",
    "\n",
    "  prompt_template = \"\"\"\n",
    "  ### 问题: {query}\\n###回答:\n",
    "  \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=128, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "  return (decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e54d617-e572-4ad6-8b98-0ee4c60e6771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ### 问题: 《鸣潮》是什么呀？\n",
      "###回答:\n",
      "  名词, n. 1 潮声; 2 噪声; 3 喧闹声;\n",
      "  adj. 喧闹的; 4 (指海洋中的潮汐)起落平稳的;\n",
      "  vt. 骚扰; 吵闹; 骚扰;(使)吵嚷;(使)喧闹\n",
      " *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"《鸣潮》是什么呀？\", model=model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9ce656-ec26-4859-b9e6-a3204992ba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ### 问题: 《鸣潮》的特色是什么？\n",
      "###回答:\n",
      "  :\n",
      "  - `双曲网格（双曲网格，即对称度数大于2的网格，或者对称度数小于等于2但至少有一条对称轴的网格）`,\n",
      "  - `环路(Cycle)`,\n",
      "  - `多环路(MultiCycle)`,\n",
      "  - `连体(Connectivity)`,\n",
      "- 鸣潮中的连体属性(Connectivity)是双相流(Two-phase flow)的有效描述方案，其中两个相交相交两个相交两个相交两个相交两个相交两个相交两个相\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"《鸣潮》的特色是什么？\", model=model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79047855-95f7-46d0-a61d-91ab83dfe5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ### 问题: 今汐是谁？\n",
      "###回答:\n",
      "  :  :red_heart:/red_heart:/red_heart: **:red_heart:/red_heart:/red_heart:** :red_heart:/red_heart:/red_heart: :red<br>\n",
      "  > *今天是06月!06日*\n",
      "  <img src='https://cdn.jsdelivr.net/gh/zcx123456a/zcx123456/static/img/1.png'>\n",
      "  ##  :blue_heart:/red_heart: **:red_heart:/red_heart:/\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"今汐是谁？\", model=model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46ac350b-ad2a-4c70-a202-2668fa7a286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ### 问题: 今汐是有什么技能？\n",
      "###回答:\n",
      "  _0034:\n",
      "    - 一旦进入暗黑之门, 就可以自由的行走整个世界。\n",
      "`\n",
      "# 2.7.4246591-4\n",
      "```java\n",
      "    class Test\n",
      "      private String qName;\n",
      "    - public Test(String questionId) {\n",
      "      super();\n",
      "      this.qName = questionId;\n",
      "    }\n",
      " ```\n",
      "```sh\n",
      "$ cd\n",
      "$ git update-index --ignore-submodules --refresh\n",
      "$ git update-index --ignore-submodules --refresh\n",
      "$ git update-index --ignore-\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"今汐是有什么技能？\", model=model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4a9635d-d096-4964-bdf2-b8cda0f94b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ### 问题: 对于XP党来说，抽取今汐是否值得抽取？\n",
      "###回答:\n",
      "  为一个新英雄，不看立绘，仅看定位上来说，这是一个主战的双打坦克型辅助，定位上和老牌坦克辅助小公枪差距不是很大。\n",
      "  在对练环境中，因为大家有充足的资源去培养自己的主力，现在对练环境其实是一个大规模5打4的对抗，也就是你这边除了6个主力，有一个辅助的位置是给敌方补位的，换句话说，哪怕是我这边满级的六位主力，如果对方的六位主力都是满级的情况下，那我的这六位主力，如果一个不配合好了就会输\n"
     ]
    }
   ],
   "source": [
    "result = get_completion(query=\"对于XP党来说，抽取今汐是否值得抽取？\", model=model, tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a1eb4-7d0c-48ce-b3d7-2edb30a5d2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
