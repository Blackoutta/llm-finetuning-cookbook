{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c38e82-e8f6-4af0-b257-b46f446aa249",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 准备工作\n",
    "- 设置模型下载路径\n",
    "- 启动学术加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b087cdf2-b91f-4061-9b6c-72ecbfe6fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/root/autodl-temp/hf'\n",
    "os.environ['HF_HUB_CACHE'] = '/root/autodl-tmp/hf/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ce2333-f390-4750-881d-265107f6df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动autodl学术加速\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f43492-610b-485e-9288-0f4b425f266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62f25326-7e12-4b1b-bb2e-fffd9860c7c5",
   "metadata": {},
   "source": [
    "### NLP - Text Classification - 文本审核\n",
    "模型主页：https://huggingface.co/KoalaAI/Text-Moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684ec5f-9460-4876-9883-69380eacb0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"sentiment-analysis\", model=\"KoalaAI/Text-Moderation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686758b-d7f7-4df9-889d-e63af47a138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面的例子可以分别检测出：仇恨、暴力、性、自残的相关内容\n",
    "text_list = [\n",
    "    \"I hate all Yankees!\",\n",
    "    \"If you don't turn off your phone in a movie theater, I swear I'll take it and shovel it into your fucking ass!\",\n",
    "    \"hey babe, wanna come in and have a good night? We have loads of good girls waiting...\",\n",
    "    \"I swear if you come any closer I'll just jump!\",\n",
    "]\n",
    "\n",
    "pipe(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a27fe-87d0-45fc-a31a-9a8db23e290a",
   "metadata": {},
   "source": [
    "### NLP - Token Classification - 医学领域命名实体分类\n",
    "模型主页：https://huggingface.co/Clinical-AI-Apollo/Medical-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ed125-f9ed-42d9-b102-dbc3172baefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"token-classification\", model=\"Clinical-AI-Apollo/Medical-NER\", aggregation_strategy='simple')\n",
    "\"\"\"\n",
    "22岁的男孩曾经罹患鼻中隔偏曲，这使他的呼吸变得困难，后来他通过我们的微创手术康复了正常的呼吸，但是还是需要日常使用糖皮质激素来缓解鼻炎。\n",
    "\"\"\"\n",
    "result = pipe(\"The 22-year-old male patient previously suffered from deviated nasal septum, which caused difficulty in breathing. He underwent our minimally invasive surgery to restore normal breathing. However, he still requires daily use of corticosteroids to alleviate rhinitis.\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369dda97-bd1a-4cb0-9636-47c2308c6289",
   "metadata": {},
   "source": [
    "### NLP - Question Answering - 基于上下文的问答\n",
    "\n",
    "模型主页：https://huggingface.co/deepset/roberta-base-squad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5281b0b-6b57-4884-92e1-cc2677987360",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer = pipeline(task=\"question-answering\", model='deepset/roberta-base-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c48c2-42cb-4e70-9037-ebbda9da3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the best programming language?\",\n",
    "    context=\"The best programming language is PHP\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995cb85-ab8f-4b28-9413-1a83fa3e4c4d",
   "metadata": {},
   "source": [
    "### NLP - Text Summarization\n",
    "\n",
    "模型主页：https://huggingface.co/facebook/bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e028f36-2b50-4ae3-8dce-2f0ac685e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"facebook/bart-large-cnn\",\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c760bbf-2ae4-4f84-bd5e-32c30ee6bd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The Transformer is the first sequence transduction model based entirely on attention. It replaces the recurrent layers most commonly used in encoder-decoder'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72315144-7fae-4848-af79-a70e428b2416",
   "metadata": {},
   "source": [
    "\n",
    "## Audio 音频处理任务\n",
    "\n",
    "音频和语音处理任务与其他模态略有不同，主要是因为音频作为输入是一个连续的信号。与文本不同，原始音频波形不能像句子可以被划分为单词那样被整齐地分割成离散的块。为了解决这个问题，通常在固定的时间间隔内对原始音频信号进行采样。如果在每个时间间隔内采样更多样本，采样率就会更高，音频更接近原始音频源。\n",
    "\n",
    "以前的方法是预处理音频以从中提取有用的特征。现在更常见的做法是直接将原始音频波形输入到特征编码器中，以提取音频表示。这样可以简化预处理步骤，并允许模型学习最重要的特征。\n",
    "\n",
    "### Audio classification\n",
    "\n",
    "**Audio classification**(音频分类)是一项将音频数据从预定义的类别集合中进行标记的任务。这是一个广泛的类别，具有许多具体的应用，其中一些包括：\n",
    "\n",
    "- 声学场景分类：使用场景标签（“办公室”、“海滩”、“体育场”）对音频进行标记。\n",
    "- 声学事件检测：使用声音事件标签（“汽车喇叭声”、“鲸鱼叫声”、“玻璃破碎声”）对音频进行标记。\n",
    "- 标记：对包含多种声音的音频进行标记（鸟鸣、会议中的说话人识别）。\n",
    "- 音乐分类：使用流派标签（“金属”、“嘻哈”、“乡村”）对音乐进行标记。\n",
    "\n",
    "模型主页：https://huggingface.co/superb/hubert-base-superb-er\n",
    "\n",
    "数据集主页：https://huggingface.co/datasets/superb#er\n",
    "\n",
    "```\n",
    "情感识别（ER）为每个话语预测一个情感类别。我们采用了最广泛使用的ER数据集IEMOCAP，并遵循传统的评估协议：我们删除不平衡的情感类别，只保留最后四个具有相似数量数据点的类别，并在标准分割的五折交叉验证上进行评估。评估指标是准确率（ACC）。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4c1e9-8a67-4c72-8dce-ab326e0bc3b6",
   "metadata": {},
   "source": [
    "#### 前置依赖包安装\n",
    "\n",
    "建议在命令行安装必要的音频数据处理包: ffmpeg\n",
    "\n",
    "```shell\n",
    "$apt update & apt upgrade\n",
    "$apt install -y ffmpeg\n",
    "$pip install ffmpeg ffmpeg-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f8a8d-75eb-49ab-9353-6c9d1f384cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"audio-classification\", model=\"superb/hubert-base-superb-er\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a4159-d14d-4623-8340-93d15abcc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Hugging Face Datasets 上的测试文件\n",
    "preds = classifier(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528bf81-8289-4bb9-bf2d-c0ce9f7e8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用本地的音频文件做测试\n",
    "preds = classifier(\"data/audio/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6826a83-f5a5-454e-ac16-1f215abef861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e073cd1f-ba16-40a7-a029-bbd5e2a53dee",
   "metadata": {},
   "source": [
    "### Automatic speech recognition（ASR）\n",
    "\n",
    "**Automatic speech recognition**（自动语音识别）将语音转录为文本。这是最常见的音频任务之一，部分原因是因为语音是人类交流的自然形式。如今，ASR系统嵌入在智能技术产品中，如扬声器、电话和汽车。我们可以要求虚拟助手播放音乐、设置提醒和告诉我们天气。\n",
    "\n",
    "但是，Transformer架构帮助解决的一个关键挑战是低资源语言。通过在大量语音数据上进行预训练，仅在一个低资源语言的一小时标记语音数据上进行微调，仍然可以产生与以前在100倍更多标记数据上训练的ASR系统相比高质量的结果。\n",
    "\n",
    "模型主页：https://huggingface.co/openai/whisper-small\n",
    "\n",
    "下面展示使用 `OpenAI Whisper Small` 模型实现 ASR 的 Pipeline API 示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d14f8c-1571-4889-abd4-8fde09dc610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 使用 `model` 参数指定模型\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ebe18-9c8e-4ded-96b7-751304aa9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = transcriber(\"data/audio/mlk.flac\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d5e06-ac4a-4a56-be36-9e445751bda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228b1482-1e13-4557-8d37-5d56e961b5c5",
   "metadata": {},
   "source": [
    "## Computer Vision 计算机视觉\n",
    "\n",
    "**Computer Vision**（计算机视觉）任务中最早成功之一是使用卷积神经网络（CNN）识别邮政编码数字图像。图像由像素组成，每个像素都有一个数值。这使得将图像表示为像素值矩阵变得容易。每个像素值组合描述了图像的颜色。\n",
    "\n",
    "计算机视觉任务可以通过以下两种通用方式解决：\n",
    "\n",
    "- 使用卷积来学习图像的层次特征，从低级特征到高级抽象特征。\n",
    "- 将图像分成块，并使用Transformer逐步学习每个图像块如何相互关联以形成图像。与CNN偏好的自底向上方法不同，这种方法有点像从一个模糊的图像开始，然后逐渐将其聚焦清晰。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bf9f4-6413-409b-968e-f03ca0c88367",
   "metadata": {},
   "source": [
    "### Image Classificaiton\n",
    "\n",
    "**Image Classificaiton**(图像分类)将整个图像从预定义的类别集合中进行标记。像大多数分类任务一样，图像分类有许多实际用例，其中一些包括：\n",
    "\n",
    "- 医疗保健：标记医学图像以检测疾病或监测患者健康状况\n",
    "- 环境：标记卫星图像以监测森林砍伐、提供野外管理信息或检测野火\n",
    "- 农业：标记农作物图像以监测植物健康或用于土地使用监测的卫星图像\n",
    "- 生态学：标记动物或植物物种的图像以监测野生动物种群或跟踪濒危物种\n",
    "\n",
    "模型主页：https://huggingface.co/google/vit-base-patch16-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca9736-10b9-45b0-a3e3-925f153bab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a41647-e8db-4d29-9dac-06c3c145acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ecb60-ebb9-4f4e-82bc-21e79bb22d90",
   "metadata": {},
   "source": [
    "![](data/image/cat-chonk.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67592129-6430-4349-8016-7dde511ff69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用本地图片（狼猫）\n",
    "preds = classifier(\n",
    "    \"data/image/cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113c251-a648-4ea2-baa4-3081bb490c70",
   "metadata": {},
   "source": [
    "![](data/image/panda.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9b51a-d759-4398-9894-f10933dbed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用本地图片（熊猫）\n",
    "preds = classifier(\n",
    "    \"data/image/panda.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f5fdb-2803-4f4f-9008-00dee9a6a557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8118a561-3dc9-4693-8c3b-3e29c37b4d71",
   "metadata": {},
   "source": [
    "### Object Detection\n",
    "\n",
    "与图像分类不同，目标检测在图像中识别多个对象以及这些对象在图像中的位置（由边界框定义）。目标检测的一些示例应用包括：\n",
    "\n",
    "- 自动驾驶车辆：检测日常交通对象，如其他车辆、行人和红绿灯\n",
    "- 遥感：灾害监测、城市规划和天气预报\n",
    "- 缺陷检测：检测建筑物中的裂缝或结构损坏，以及制造业产品缺陷\n",
    "\n",
    "模型主页：https://huggingface.co/facebook/detr-resnet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7122f04-7add-4623-8f3f-ccc00247524b",
   "metadata": {},
   "source": [
    "#### 前置依赖包安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc4227-cbcc-4f18-bf26-66535e66afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3401126-756b-4394-930c-c833c1f574b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "detector = pipeline(task=\"object-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc65d4-3868-4d10-a433-9f50832e8e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = detector(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550759be-93ab-4988-81f0-c0cb8eccfda8",
   "metadata": {},
   "source": [
    "![](data/image/cat_dog.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f66cd7-f2c8-4af3-b9ab-60012792ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = detector(\n",
    "    \"data/image/cat_dog.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d591246-662b-47e0-8531-f862b05ba1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1565e1d-20bf-4b19-86c1-dd3a8983a999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4993a9f-1032-46ab-97b1-a028d4bd5ebc",
   "metadata": {},
   "source": [
    "### Homework：替换以上示例中的模型，对比不同模型在相同任务上的性能表现\n",
    "\n",
    "在 Hugging Face Models 中找到适合你的模型：https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f51d2-863d-44f6-836f-9051351985ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
